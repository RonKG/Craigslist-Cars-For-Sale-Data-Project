{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "colab": {
      "name": "Craigslist Part 2.2 Downloading Images from Craigslist",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2055KuKhF1JD"
      },
      "source": [
        "# <font color='red'> Import libraries </font>"
      ],
      "id": "2055KuKhF1JD"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nxDudMFGF1JJ"
      },
      "source": [
        "# work with dataframes\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# we'll use this to store the a dataframe to csv at a later stage\n",
        "import csv\n",
        "\n",
        "# make HTTP requests to a specified URL\n",
        "import requests\n",
        "\n",
        "# web scraping library\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "# time management\n",
        "import time\n",
        "from random import randint\n",
        "# from collections import Counter\n",
        "\n",
        "# regular expressions\n",
        "import re\n",
        "\n",
        "# io operations \n",
        "import os\n",
        "\n",
        "# read  and write img links\n",
        "import json"
      ],
      "id": "nxDudMFGF1JJ",
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ntXv0hWtNrRX",
        "outputId": "aed9b574-cba1-4d88-9277-b79fa153bb33"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "id": "ntXv0hWtNrRX",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e4f54678"
      },
      "source": [
        "# <font color='red'> Download Images <font/>"
      ],
      "id": "e4f54678"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a53f061f"
      },
      "source": [
        "### create dict of postID , images to download\n",
        "\n",
        "# get image links\n",
        "img_urls = []\n",
        "\n",
        "# loop through the city pages\n",
        "for url in list_of_cities:\n",
        "    # instantiate a BS object\n",
        "    soup = BeautifulSoup(requests.get(url).text, 'lxml')\n",
        "\n",
        "    # img with dimensions place holder\n",
        "    # img_url = 'https://images.craigslist.org/{}_1200x900.jpg' <--- for high resolution images\n",
        "    img_url = 'https://images.craigslist.org/{}_300x300.jpg'\n",
        "    for i, (a_img, a_title) in enumerate(zip(soup.select('.result-row a.result-image.gallery[data-ids]'),\n",
        "                              soup.select('.result-row a.result-title')), 1):\n",
        "        # create a list of images for each vehicle\n",
        "        img_links = []\n",
        "        \n",
        "        # create a dictionary to store (postID, imageLinks)        \n",
        "        d = {}\n",
        "        \n",
        "        # default dict setup\n",
        "        d.setdefault(a_title['id'],[])\n",
        "        \n",
        "        # for each postID get img links\n",
        "        for data_id in [s.split(':')[1] for s in a_img['data-ids'].split(',')]:\n",
        "            # store img links\n",
        "            img_links.append(img_url.format(data_id))\n",
        "        \n",
        "        # append postID and list of img links\n",
        "        d[a_title['id']].append(img_links)\n",
        "        img_urls.append(d)        \n",
        "        time.sleep(randint(0,1))"
      ],
      "id": "a53f061f",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "292e812c"
      },
      "source": [
        "# save image dicts in json\n",
        "try:\n",
        "    with open('craigslistproject/c_img_urls.json', 'w', encoding='utf-8') as f:\n",
        "        json.dump(img_urls, f, ensure_ascii=False, indent=4)\n",
        "except IOError:\n",
        "    print(\"I/O error\")"
      ],
      "id": "292e812c",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "076c28c8"
      },
      "source": [
        "# open json list of dicts\n",
        "with open('craigslistproject/c_img_urls.json') as f:\n",
        "  img_paths = json.load(f)"
      ],
      "id": "076c28c8",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6390a800"
      },
      "source": [
        "# helper method to create directories in local\n",
        "def createFolder(directory):\n",
        "    try:\n",
        "        if not os.path.exists(directory):\n",
        "            os.makedirs(directory)\n",
        "    except OSError:\n",
        "        print ('Error: Creating directory. ' +  directory)"
      ],
      "id": "6390a800",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "caac85ca"
      },
      "source": [
        "# iterate through list of dicts\n",
        "for car in img_paths:\n",
        "    # for each postID get links\n",
        "    for post_id, photo_links in car.items():\n",
        "        # image name increment\n",
        "        img_number = 0\n",
        "        # index through list of img urls\n",
        "        for link in photo_links[0]:\n",
        "            Picture_request = requests.get(link)\n",
        "            # create folder name matching postID\n",
        "            createFolder('craigslist_imgs\\\\' + post_id)\n",
        "            # check if img is present\n",
        "            if Picture_request.status_code == 200:\n",
        "                # if present create img name\n",
        "                f_name = post_id + '_{}.jpg'.format(img_number)\n",
        "                # create image path for storage\n",
        "                f_path = r'c:\\datascience\\craigslist_imgs\\{}{}{}'.format(post_id,'\\\\', f_name)\n",
        "                # store image in created directory\n",
        "                with open(f_path, 'wb') as f:\n",
        "                    for chunk in Picture_request.iter_content(chunk_size=1024):\n",
        "                        length = f.write(chunk)\n",
        "                img_number +=1"
      ],
      "id": "caac85ca",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kz7Ml1aMb_R0"
      },
      "source": [
        "## <font color='red'> Redownload Failed Images <font/>"
      ],
      "id": "kz7Ml1aMb_R0"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FkDo-owWbvn4"
      },
      "source": [
        "# # iterate through list of downloaded folders\n",
        "# test = img_paths\n",
        "# count = 1\n",
        "# remaining = []\n",
        "\n",
        "# # get the names f downloaded postIDs\n",
        "# for car in test:\n",
        "#     # for each postID get links 9 (list if dicts)\n",
        "#     for post_id, photo_links in car.items():\n",
        "#         if post_id not in remove_folders:\n",
        "#             remaining.append(car)\n",
        "    \n",
        "# len(test), len(remaining), len(remove_folders)\n",
        "\n",
        "\n",
        "# # reinitiate downloads\n",
        "# # iterate through list of dicts\n",
        "# for car in remaining:\n",
        "#     # for each postID get links 9 (list if dicts)\n",
        "#     for post_id, photo_links in car.items():\n",
        "#         # image name incrementer\n",
        "#         img_number = 0\n",
        "#         # index through list of img urls in dict item\n",
        "#         for link in photo_links[0]:\n",
        "#             Picture_request = requests.get(link)\n",
        "#             # create folder with postID name\n",
        "#             createFolder('B:\\craigslist_imgs\\\\' + post_id)\n",
        "#             # check if img is present\n",
        "#             if Picture_request.status_code == 200:\n",
        "#                 # if present create img name\n",
        "#                 f_name = post_id + '_{}.jpg'.format(img_number)\n",
        "#                 # create image path for local storage\n",
        "#                 f_path = r'B:\\craigslist_imgs\\{}{}{}'.format(post_id,'\\\\', f_name)\n",
        "#                 # store image in created directory\n",
        "#                 with open(f_path, 'wb') as f:\n",
        "#                     for chunk in Picture_request.iter_content(chunk_size=1024):\n",
        "#                         length = f.write(chunk)\n",
        "#                 img_number +=1\n",
        "#                 time.sleep(randint(0,1))"
      ],
      "id": "FkDo-owWbvn4",
      "execution_count": null,
      "outputs": []
    }
  ]
}